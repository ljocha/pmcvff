{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Property Map Collective Variable Force Field Correction Pipeline\n",
    "---\n",
    "The pipeline generates force field corrections in .pdb format and is divided into these steps:\n",
    "\n",
    "1. [Molecule shape processing](#1.-Molecule-shape-processing)\n",
    "2. [Preparation of environment and molecule](#2.-Preparation-of-environment-and-molecule)\n",
    "3. [Generation of representative configurations](#3.-Generation-of-representative-configurations)\n",
    "4. [Accurate and innacurate energy evaluation](#4.-Accurate-and-innacurate-energy-evaluation)\n",
    "5. [Define correction of force field](#5.-Define-correction-of-force-field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "# import chemical software\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit import Chem\n",
    "from tqdm.notebook import tqdm\n",
    "from molvs import Standardizer\n",
    "import nglview as nv\n",
    "import pytraj as pt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import custom libraries\n",
    "from draw_3d import drawit\n",
    "from modules.convert import convert_to_orca_methods\n",
    "from modules.plot_graph import plot_landmarks\n",
    "from modules.gmx_orca.gmx_orca_run import gmx_run, orca_run, parallel_wait\n",
    "from modules.replace import replace_text_for_embedding\n",
    "\n",
    "# path to needed scripts\n",
    "orca_job_check = '/home/base/modules/orcajobcheck.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Molecule shape processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify input of desired molecule in SMILES\n",
    "smiles_molecule = 'CC1=C(C=C(C=C1)NC(=O)C2=CC=C(C=C2)C[NH+]3CCN(CC3)C)NC4=NC=CC(=N4)C5=CN=CC=C5'\n",
    "\n",
    "# set visualization parameters\n",
    "# ... add Indices to molecule image\n",
    "IPythonConsole.drawOptions.addAtomIndices = True\n",
    "\n",
    "# ... set molecule size\n",
    "IPythonConsole.molSize = 900,900\n",
    "\n",
    "\n",
    "molecule = Chem.MolFromSmiles(smiles_molecule)\n",
    "molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Standardizer()\n",
    "molecule = s.standardize(molecule)\n",
    "molecule = Chem.AddHs(molecule)\n",
    "natoms = molecule.GetNumAtoms()\n",
    "charge = Chem.rdmolops.GetFormalCharge(molecule)\n",
    "\n",
    "molecule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Set the lowest energy configuration\n",
    "Perform basic energy minimisation by running [Merck molecular force field (MMFF94)](https://open-babel.readthedocs.io/en/latest/Forcefields/mmff94.html) and choose the conformation with the lowest energy.\n",
    "\n",
    "Visualize the configuration with lowest energy in 3D afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of configurations to generate\n",
    "numc = 50\n",
    "\n",
    "Chem.AllChem.EmbedMultipleConfs(molecule, clearConfs=True, numConfs=numc)\n",
    "\n",
    "# run MMFF94\n",
    "optim = Chem.AllChem.MMFFOptimizeMoleculeConfs(molecule)\n",
    "\n",
    "minid = -1\n",
    "minene = sys.float_info.max\n",
    "for i in range(len(optim)):\n",
    "    if optim[i][1] < minene:\n",
    "        minene = optim[i][1]\n",
    "        minid = i\n",
    "\n",
    "# write to file molekula.mol for further processing\n",
    "writer = Chem.SDWriter('molekula.mol')\n",
    "writer.write(molecule, confId = minid)\n",
    "\n",
    "drawit(molecule, confId = minid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Detect torsion angles\n",
    "Detect torsions based on pattern in *smarts*. Output can be checked on 2D visualization in step [2. Molecule shape processing](#2.-Molecule-shape-processing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_smarts = '''[!$([NH]!@C(=O))&!D1&!$(*#*)&!$([C;H3])&!$([O;H1])&!$([N;H3])]-&!@\n",
    "                 [!$([NH]!@C(=O))&!D1&!$(*#*)&!$([C;H3])&!$([O;H1])&!$([N;H3])]'''\n",
    "\n",
    "rotatable_bond = Chem.MolFromSmarts(bond_smarts)\n",
    "rotatables = molecule.GetSubstructMatches(rotatable_bond)\n",
    "print(f'Rotatables: {rotatables}')\n",
    "\n",
    "\n",
    "torsions = []\n",
    "for rotatable in rotatables:\n",
    "    pairs1 = []\n",
    "    pairs2 = []\n",
    "    for bond in molecule.GetBonds():\n",
    "        if rotatable[0] == bond.GetBeginAtomIdx() and rotatable[1] != bond.GetEndAtomIdx():\n",
    "            pairs1.append([bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()])\n",
    "        if rotatable[1] == bond.GetBeginAtomIdx() and rotatable[0] != bond.GetEndAtomIdx():\n",
    "            pairs2.append([bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()])\n",
    "    torsions.append([pairs1[0][1], pairs1[0][0], pairs2[0][0], pairs2[0][1]])\n",
    "print(f'Torsions: {torsions}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparation of environment and molecule\n",
    "### 2.1 Perform energetic minimisation\n",
    "Generate config file and other files needed for energetic minimisation. During generation an ordering of atoms will get wrong. This is fixed afterwards from output files to fit the minimised molecule.\n",
    "\n",
    "Finally perform an energetic minimisation using [Gromacs](https://www.gromacs.org/). This pipeline uses wrapper so the Gromacs can be run independently to this environment. Please read the wrapper [documentation](https://github.com/CERIT-SC/pmcvff-correction/tree/jupyter-refactor/modules/gmx_orca) before you interact with any Gromacs command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"em/em.mdp\", \"w\") as emfile:\n",
    "    emfile.write(\"integrator          =  steep\\n\")\n",
    "    emfile.write(\"nsteps              =  100000\\n\")\n",
    "    emfile.write(\"emtol               =  0\\n\")\n",
    "    emfile.write(\"emstep              =  0.1\\n\")\n",
    "    emfile.write(\"nstcomm             =  1\\n\")\n",
    "    emfile.write(\"nstxout             =  100\\n\")\n",
    "    emfile.write(\"nstvout             =  100\\n\")\n",
    "    emfile.write(\"nstfout             =  0\\n\")\n",
    "    emfile.write(\"nstlog              =  100\\n\")\n",
    "    emfile.write(\"nstenergy           =  100\\n\")\n",
    "    emfile.write(\"nstlist             =  1\\n\")\n",
    "    emfile.write(\"ns_type             =  grid\\n\")\n",
    "    emfile.write(\"coulombtype         =  cut-off\\n\")\n",
    "    emfile.write(\"rlist               =  1.4\\n\")\n",
    "    emfile.write(\"rcoulomb            =  1.4\\n\")\n",
    "    emfile.write(\"rvdw                =  1.4\\n\")\n",
    "    emfile.write(\"energygrps          =  System\\n\")\n",
    "    emfile.write(\"epsilon-r           =  80\\n\")\n",
    "    emfile.write(\"\\n\")\n",
    "shutil.copy(\"MOL_GMX.gro\", \"em/\")\n",
    "shutil.copy(\"MOL_GMX.top\", \"em/\")\n",
    "\n",
    "\n",
    "!antechamber -i molekula.mol -fi mdl -o molekula.prepi -fo prepi -c bcc -nc {charge} && \\\n",
    "parmchk2 -i molekula.prepi -f prepi -o molekula.frcmod && \\\n",
    "tleap -f tleapin.txt && \\\n",
    "acpype -p molekula.prmtop -x molekula.inpcrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix ordering of atoms\n",
    "\n",
    "order_before = []\n",
    "with open('sqm.pdb','r') as pdbfile:\n",
    "    for atom in pdbfile.readlines():\n",
    "        order_before.append(atom.split()[2])\n",
    "        \n",
    "order_after = []\n",
    "with open('MOL_GMX.gro','r') as grofile:\n",
    "    for atom in grofile.readlines():\n",
    "        if atom.startswith('    1  MOL'):\n",
    "            order_after.append(atom.split()[2])\n",
    "\n",
    "            \n",
    "torsions_new = []\n",
    "torsion_new = []\n",
    "for torsion in torsions:\n",
    "    for i in torsion:       \n",
    "        torsion_new.append(order_after.index(order_before[i])+1)\n",
    "    torsions_new.append(torsion_new)\n",
    "    torsion_new = []\n",
    "    \n",
    "torsions = torsions_new\n",
    "print(f'New torsions: {torsions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmx_run('editconf -f MOL_GMX -o box -c -box 3 3 3', workdir='em')\n",
    "gmx_run('grompp -f em.mdp -c box -p MOL_GMX -o em1', workdir='em')\n",
    "gmx_run('mdrun -deffnm em1 -ntomp 2', workdir='em')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Perform molecular dynamics simulation\n",
    "Create config file and perform molecular dynamics simulation. Simulation trajectory can be visualized.\n",
    "\n",
    "Afterwards a [periodic boundary conditions](https://www.gromacs.org/Documentation_of_outdated_versions/Terminology/Periodic_Boundary_Conditions) must be applied so the molecule \"does not jump out of the box\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('md/md.mdp', 'w') as mdfile:\n",
    "    mdfile.write('integrator          = sd\\n')\n",
    "    mdfile.write('nsteps              = 100000\\n')\n",
    "    mdfile.write('dt                  = 0.001\\n')\n",
    "    mdfile.write('nstxout             = 1000\\n')\n",
    "    mdfile.write('nstvout             = 1000\\n')\n",
    "    mdfile.write('nstenergy           = 1000\\n')\n",
    "    mdfile.write('nstlog              = 1000\\n')\n",
    "    mdfile.write('continuation        = no\\n')\n",
    "    mdfile.write('constraints         = none\\n')\n",
    "    mdfile.write('cutoff-scheme       = Verlet\\n')\n",
    "    mdfile.write('ns_type             = grid\\n')\n",
    "    mdfile.write('nstlist             = 1\\n')\n",
    "    mdfile.write('rlist               = 1.4\\n')\n",
    "    mdfile.write('rcoulomb            = 1.4\\n')\n",
    "    mdfile.write('rvdw                = 1.4\\n')\n",
    "    mdfile.write('coulombtype         = cut-off\\n')\n",
    "    mdfile.write('tcoupl              = V-rescale\\n')\n",
    "    mdfile.write('tc-grps             = system\\n')\n",
    "    mdfile.write('tau_t               = 0.1\\n')\n",
    "    mdfile.write('ref_t               = 300\\n')\n",
    "    mdfile.write('pcoupl              = no\\n')\n",
    "    mdfile.write('pbc                 = xyz\\n')\n",
    "    mdfile.write('gen_vel             = yes\\n')\n",
    "    mdfile.write('epsilon-r           = 80\\n')\n",
    "    mdfile.write('\\n')\n",
    "shutil.copy('em/em1.gro', 'md/')\n",
    "shutil.copy('MOL_GMX.top', 'md/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmx_run('grompp -f md.mdp -c em1 -p MOL_GMX -o md1', workdir='md')\n",
    "gmx_run('mdrun -deffnm md1 -ntomp 2', workdir='md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert trajectory to .pdb format so it can be visualized\n",
    "\n",
    "# select group for trjconv evaluation output\n",
    "# Group     0 (         System)\n",
    "# Group     1 (          Other)\n",
    "# Group     2 (            MOL)\n",
    "group = '0'\n",
    "\n",
    "\n",
    "gmx_run('trjconv -pbc nojump -s md1.tpr -f md1.trr -o outTraj.pdb', workdir='md', groups=group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the molecular dynamics trajectory\n",
    "traj = pt.load('md/outTraj.pdb')\n",
    "view = nv.show_pytraj(traj)\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix periodic boundaries errors \n",
    "\n",
    "# select group for trjconv evaluation output\n",
    "# Group     0 (         System)\n",
    "# Group     1 (          Other)\n",
    "# Group     2 (            MOL)\n",
    "group = '1'\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(torsions))):\n",
    "    fr = str(float(100-len(torsions)+i)-0.01)\n",
    "    to = str(float(100-len(torsions)+i)+0.01)\n",
    "    gmx_run(f'trjconv -pbc nojump -s md1 -f md1 -o frame{i}.gro -b {fr} -e {to}<<EOF\\n0\\nEOF',\n",
    "            workdir='md',\n",
    "            groups=group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generation of representative configurations\n",
    "### 3.1 Trajectory generation\n",
    "Create config file and *plumed.dat* file. Based on these files run the simulation (with metadynamics) to generate a trajectory.\n",
    "\n",
    "[Plumed](https://www.plumed.org/) is used to run metadynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mtd/mtd.mdp', 'w') as mtdfile:\n",
    "    mtdfile.write('integrator          = sd\\n')\n",
    "    mtdfile.write('nsteps              = 10000000\\n')\n",
    "    mtdfile.write('dt                  = 0.001\\n')\n",
    "    mtdfile.write('nstxout             = 10000\\n')\n",
    "    mtdfile.write('nstvout             = 10000\\n')\n",
    "    mtdfile.write('nstenergy           = 1000\\n')\n",
    "    mtdfile.write('nstlog              = 1000\\n')\n",
    "    mtdfile.write('continuation        = no\\n')\n",
    "    mtdfile.write('constraints         = none\\n')\n",
    "    mtdfile.write('cutoff-scheme       = Verlet\\n')\n",
    "    mtdfile.write('ns_type             = grid\\n')\n",
    "    mtdfile.write('nstlist             = 1\\n')\n",
    "    mtdfile.write('rlist               = 1.4\\n')\n",
    "    mtdfile.write('rcoulomb            = 1.4\\n')\n",
    "    mtdfile.write('rvdw                = 1.4\\n')\n",
    "    mtdfile.write('coulombtype         = cut-off\\n')\n",
    "    mtdfile.write('tcoupl              = V-rescale\\n')\n",
    "    mtdfile.write('tc-grps             = system\\n')\n",
    "    mtdfile.write('tau_t               = 0.1\\n')\n",
    "    mtdfile.write('ref_t               = 300\\n')\n",
    "    mtdfile.write('pcoupl              = no\\n')\n",
    "    mtdfile.write('pbc                 = xyz\\n')\n",
    "    mtdfile.write('gen_vel             = yes\\n')\n",
    "    mtdfile.write('epsilon-r           = 80\\n')\n",
    "    mtdfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(torsions)):\n",
    "    if not os.path.exists(f'mtd/w{i}'):\n",
    "        os.mkdir(f'mtd/w{i}'')\n",
    "        \n",
    "    with open(f'mtd/w{i}/plumed.dat', \"w\") as plumeddat:\n",
    "        plumeddat.write('RANDOM_EXCHANGES\\n')\n",
    "        plumeddat.write(f'WHOLEMOLECULES ENTITY0=1-{natoms}\\n')\n",
    "        for j in range(len(torsions)):\n",
    "            plumeddat.write(f'''TORSION ATOMS={torsions[j][0]},{torsions[j][1]},\n",
    "                                              {torsions[j][2]},{torsions[j][3]} LABEL=cv{j+1}\\n''')\n",
    "        plumeddat.write(f'''METAD ARG=cv{i+1} HEIGHT=0.5 SIGMA=0.3 PACE=1000 GRID_MIN=-pi \n",
    "                            GRID_MAX=pi BIASFACTOR=15 LABEL=be\\n''')\n",
    "        cvs = \"\"\n",
    "        for j in range(len(torsions)):\n",
    "            cvs = cvs + f'cv{j+1},'\n",
    "        cvs = cvs[:-1]\n",
    "        plumeddat.write(f'PRINT ARG={cvs} STRIDE=1000 FILE=COLVAR\\n')\n",
    "        plumeddat.write('PRINT ARG=be.bias STRIDE=1000 FILE=BIAS\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.copy('MOL_GMX.top', 'mtd/')\n",
    "\n",
    "# perform preprocessing before generation of the trajectory\n",
    "for i in tqdm(range(len(torsions))):\n",
    "    shutil.copy(f'md/frame{i}.gro', f'mtd/w{i}/')\n",
    "    gmx_run(f'grompp -f mtd.mdp -c w{i}/frame{i} -p MOL_GMX -o w{i}/mtd1',\n",
    "            workdir='mtd',\n",
    "            parallel=True)\n",
    "parallel_wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = ''\n",
    "for i in range(len(torsions)):\n",
    "    directories = directories + f'w{i} '\n",
    "\n",
    "# see mdrunlog in mtd directory for insight into running \n",
    "# mdrun simulation (e.g 'tail -f mdrunlog')\n",
    "gmx_run(f'mdrun -g mdrunlog -ntomp 1 -deffnm mtd1 -replex 500 -plumed plumed.dat -multidir {directories}', \n",
    "        workdir='mtd', \n",
    "        mpi_run=len(torsions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Configurations clustering\n",
    "Concatinate all the trajectories that simulation produced. Then cluster this trajectory to groups for which one representative configuration is chosen (*cutoff* can be modified for more/less clusters).\n",
    "\n",
    "Result of [Gromacs clustering](https://manual.gromacs.org/documentation/current/onlinehelp/gmx-cluster.html) is .pdb file containing all representative configurations. These must be divided into separate .pdb files for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories = ''\n",
    "for i in range(len(torsions)):\n",
    "    trajectories = trajectories + f'mtd/w{i}/mtd1.trr '\n",
    "\n",
    "# concatinate trajectories    \n",
    "gmx_run(f'trjcat -f {trajectories} -cat -o mtd/mtd1.trr')\n",
    "\n",
    "# make index file with non-hydrogen atoms\n",
    "gmx_run(\"make_ndx -f md/md1.tpr -o mtd/index.ndx\", make_ndx=\"1&!aH*\")\n",
    "\n",
    "\n",
    "# select groups for cluster evaluation output\n",
    "# Group     0 (         System)\n",
    "# Group     1 (          Other)\n",
    "# Group     2 (            MOL)\n",
    "# Group     3 (         Custom)\n",
    "groups = '30'\n",
    "\n",
    "gmx_run(f'''cluster -method gromos -f mtd/mtd1.trr -s mtd/w0/mtd1.tpr -n mtd/index.ndx -cutoff 0.15 \n",
    "        -cl clustering/outClusters.pdb''', groups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide all clusters from clustering output file \n",
    "# to single files and index them from 0.\n",
    "# Also fix missing element of each ATOM on \n",
    "# line 77 (by pdb format specification)\n",
    "cluster_index = 0\n",
    "i = 0\n",
    "\n",
    "with open('clustering/outCluster.pdb') as infile:\n",
    "    clusters = infile.readlines()\n",
    "    while i < len(clusters):\n",
    "        with open(f'clustering/outClustersPDB/outCluster{cluster_index}.pdb', 'w') as outfile:\n",
    "            for line in clusters[i:]:\n",
    "                split_line = line.split()\n",
    "                if split_line[0] == 'ATOM':\n",
    "                    line = line[:77] + split_line[2][0] + '\\n'\n",
    "                out.write(line)\n",
    "                i += 1\n",
    "                if line == 'ENDMDL\\n':\n",
    "                    break\n",
    "            cluster_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Visualize landmarks\n",
    "Goal of this part is to compute embeddings which are visualized afterwards. Each step is performed on the trajectory which results from previous step. Base trajectory used in 1st step is the concatinated trajectory from metadynamics simulation.\n",
    "\n",
    "1. Apply periodic boundary conditions to metadynamics trajectory\n",
    "2. Perform fitting on the trajectory\n",
    "3. Remove Hydrogen\n",
    "4. Train [parmtSNEcv](https://gitlab.ics.muni.cz/spiwokv/parmtSNEcv)\n",
    "5. Compute embeddings\n",
    "\n",
    "Finally visualize all generated configurations from metadynamics trajectory in contrast to representative clusters configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group     0 (         System)\n",
    "# Group     1 (          Other)\n",
    "# Group     2 (            MOL)\n",
    "# Group     3 (         Custom)\n",
    "# select group for periodic boundaries check output:\n",
    "group = '0'\n",
    "gmx_run('trjconv -f mtd/mtd1.trr -s mtd/w0/mtd1.tpr -pbc mol -o visualization/traj/mtd1_nopbc.xtc', groups=group)\n",
    "\n",
    "# select groups for fitting and output:\n",
    "groups = '00'\n",
    "gmx_run('''trjconv -f visualization/traj/mtd1_nopbc.xtc -s clustering/outClustersPDB/outCluster0.pdb \n",
    "        -fit rot+trans -o visualization/traj/mtd1_fit.xtc''', groups=groups)\n",
    "\n",
    "# select group for no Hydrogen output:\n",
    "group = '3'\n",
    "gmx_run('trjconv -f visualization/traj/mtd1_fit.xtc -n mtd/index.ndx -o visualization/traj/mtd1_fit_noH.xtc',\n",
    "        groups=group)\n",
    "\n",
    "# select groups for size of the box and output:\n",
    "groups = '33'\n",
    "gmx_run('''editconf -f clustering/outClustersPDB/outCluster0.pdb -n mtd/index.ndx -box 3 3 3 -c\n",
    "        -o visualization/ref.pdb''', groups=groups)\n",
    "\n",
    "\n",
    "# train parmtSNEcv\n",
    "!parmtSNEcv -i visualization/traj/mtd1_fit_noH.xtc -p visualization/ref.pdb -boxx 3 -boxy 3 -boxz 3 -dim 2 \\\n",
    " -layers 2 -o visualization/out.txt -plumed visualization/plumed.dat -epochs 2000\n",
    "\n",
    "\n",
    "# modify plumed.dat to compute embedding in every step and change name of file for *** mtd trajectory ***\n",
    "replace_text_for_embedding('visualization/plumed.dat', stride=(100, 1), file_name=('COLVAR', '2d_embedding'))\n",
    "\n",
    "# fix weights of atoms\n",
    "replace_text_for_embedding('visualization/ref.pdb', weight=(0.00, 1.00))\n",
    "\n",
    "# run as plumed\n",
    "gmx_run('driver --plumed visualization/plumed.dat --mf_xtc visualization/traj/mtd1_fit.xtc')\n",
    "\n",
    "# modify plumed.dat to compute embedding in every step and change name of file for *** representatives ***\n",
    "replace_text_for_embedding('visualization/plumed.dat', file_name=('2d_embedding', 'landmarks'))\n",
    "\n",
    "# run as plumed\n",
    "gmx_run('driver --plumed visualization/plumed.dat --mf_pdb clustering/outClusters.pdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize configurations in contrast to representative configurations\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "x1 = []\n",
    "y1 = []\n",
    "with open(\"2d_embedding\", \"r\") as infile:\n",
    "    for line in infile.readlines()[1:]:\n",
    "        split_values = line.split()\n",
    "        x.append(split_values[1])\n",
    "        y.append(split_values[2])\n",
    "with open(\"landmarks\", \"r\") as infile:\n",
    "    for line in infile.readlines()[1:]:\n",
    "        split_values = line.split()\n",
    "        x1.append(split_values[1])\n",
    "        y1.append(split_values[2])\n",
    "        \n",
    "        \n",
    "plt.figure(figsize=(100, 50), dpi=100)\n",
    "plt.scatter(x, y, c='b', marker='.', label='All Configurations', s=2000)\n",
    "plt.scatter(x1, y1, c='r', marker='o', label='Representative configurations', s=3000)\n",
    "plt.legend(loc='upper left', prop={'size': 80})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Accurate and innacurate energy evaluation\n",
    "Accurate energy values are computed in this step using the [Orca](https://sites.google.com/site/orcainputlibrary/) quantum chemistry software. Orca uses [method files](https://sites.google.com/site/orcainputlibrary/generalinput) in exact format to perform the computations. Computation of exact energy values of each representative is composed of 3-step chain. Input for *AM1* are representative configurations defined by clustering in previous step. Each next computation is performed on the output of the previous step.\n",
    "\n",
    "1. **AM1 optimisation** (*input*: clustering results)\n",
    "2. **BP86 SVP** (*input*: AM1 output)\n",
    "3. **BP86 TZVP** (*input*: BP86 SVP output, *output*: exact energy values of representative configurations)\n",
    "\n",
    "Also each step above consists of 3 substeps:\n",
    "\n",
    "1. Convert the output of previous step to Orca compatible *.inp method*\n",
    "2. Perform Orca computation\n",
    "3. Analyse output (see logs)\n",
    "\n",
    "Please read the wrapper [documentation](https://github.com/CERIT-SC/pmcvff-correction/tree/jupyter-refactor/modules/gmx_orca) before interacting with any Orca command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix indexing of atoms because Orca indexes from zero \n",
    "orca_torsions = [[] for _ in range(len(torsions))]\n",
    "torsion_index = 0\n",
    "for torsion in torsions:\n",
    "    for atom_index in torsion:\n",
    "        orca_torsions[torsion_index].append(atom_index - 1)\n",
    "    torsion_index += 1\n",
    "torsions = orca_torsions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a list of all clusters that are considered\n",
    "# in the quantum chemistry computations. For example\n",
    "# non-converged simulation on cluster will result in\n",
    "# discarding that cluster from further computations\n",
    "#\n",
    "# ** don't forget to reset clusters variable when\n",
    "# rerunning computations as non-converged will be\n",
    "# missing **\n",
    "clusters = []\n",
    "for cluster in os.listdir('clustering/outClustersPDB'):\n",
    "    if '.pdb' in cluster:\n",
    "        clusters.append(cluster.replace('.pdb', ''))\n",
    "        \n",
    "\n",
    "# convert .pdb file to orca method\n",
    "# - method specifies which method to apply by Orca\n",
    "# - info is to specify the *charge* and *spin* of molecule\n",
    "# - nprocs is to specify the number of CPU's to use (None for default)\n",
    "# - xyz specify True to convert .xyz to orca instead\n",
    "def pdb2orca(pdb_in, orca_out, method, info, nprocs=None, xyz=False):\n",
    "    with open(pdb_in, 'r') as infile, open(orca_out, 'w') as outfile:\n",
    "        outfile.write(f'{method}\\n')\n",
    "        \n",
    "        if nprocs:\n",
    "            outfile.write(f'%pal\\n')\n",
    "            outfile.write(f'nprocs {str(nprocs)}\\n')\n",
    "            outfile.write(f'end\\n')\n",
    "            \n",
    "        outfile.write('%geom\\n')\n",
    "        outfile.write('Constraints\\n')\n",
    "        \n",
    "        # write torsions\n",
    "        for torsions_list in torsions:\n",
    "            outfile.write('{D ')\n",
    "            for torsion in torsions_list:\n",
    "                outfile.write(f'{str(torsion)} ')\n",
    "            outfile.write('C}\\n')\n",
    "        \n",
    "        outfile.write('end\\n')\n",
    "        outfile.write('end\\n\\n')\n",
    "        outfile.write(f'*xyz {info[0]} {info[1]}\\n')\n",
    "        \n",
    "        # copy atom information from input and modify\n",
    "        # to fit the orca method format\n",
    "        if xyz:\n",
    "            for line in infile.readlines()[2:]:\n",
    "                outfile.write(f'{line}')\n",
    "        else:\n",
    "            for line in infile.readlines():\n",
    "                splitline = line.split()\n",
    "                if splitline[0] == 'ATOM':\n",
    "                    orca_line = f'{splitline[10]}       {splitline[5]}      {splitline[6]}       {splitline[7]}\\n'\n",
    "                    outfile.write(orca_line)\n",
    "                \n",
    "        outfile.write('*\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 AM1 geometry optimisation method\n",
    "Perform the semi-empirical [Austin Model 1](https://en.wikipedia.org/wiki/Austin_Model_1) method on representatives. It can be understood as kind of preprocessing (optimisation) which uses approximations instead of exact calculations to speed up the process of the next simulation. Output of AM1 is input for the next [BP86 SVP method.](###-4.3-BP86-SVP-method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the representatives from clustering to fit \n",
    "# the AM1 Orca method\n",
    "\n",
    "# specify AM1 method\n",
    "method = '!AM1 Opt'\n",
    "\n",
    "# input directory of .pdb representatives\n",
    "input_dir = 'clustering/outClustersPDB/'\n",
    "\n",
    "# output directory where converted .inp Orca \n",
    "# methods will be placed\n",
    "output_dir = 'am1/input/'\n",
    "\n",
    "# specify spin (and charge)\n",
    "spin = 1\n",
    "# charge is specified in the first step \n",
    "# of 1. Molecule shape processing\n",
    "# charge = XXX\n",
    "\n",
    "\n",
    "for pdb in tqdm(os.listdir(input_dir)):\n",
    "    if '.pdb' in pdb:\n",
    "        infile = input_dir + pdb\n",
    "        outfile = output_dir + pdb.replace('pdb', 'inp')\n",
    "\n",
    "        pdb2orca(infile, outfile, method, (charge,spin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the AM1 method optimisation\n",
    "\n",
    "input_path = \"am1/input/\"\n",
    "output_path = \"am1/output/\"\n",
    "\n",
    "\n",
    "for method_file in os.listdir(input_path):\n",
    "    if '.inp' in method_file:\n",
    "        log_file = method_file.replace('inp', 'out')\n",
    "        cluster_dir = method_file.replace('.inp', '/')\n",
    "        cluster_dir_path = output_path + cluster_dir\n",
    "\n",
    "        if not os.path.exists(cluster_dir_path):\n",
    "            os.mkdir(cluster_dir_path)    \n",
    "        shutil.copy(input_path + method_file, cluster_dir_path)\n",
    "\n",
    "        #temporary log !!!!!!!!!!!!!\n",
    "        orca_run(method_file, cluster_dir_path + log_file, workdir=cluster_dir_path, parallel=True)\n",
    "    \n",
    "parallel_wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the output of AM1 optimisation\n",
    "\n",
    "for cluster in clusters:\n",
    "    with open(f'{output_path}{cluster}/{cluster}.out') as infile:\n",
    "        orca_log = infile.read()\n",
    "        if '****ORCA TERMINATED NORMALLY****' not in orca_log:\n",
    "            print(orca_log)\n",
    "            raise SystemExit(f'Error in AM1 method of {cluster}. You should not continue computation!')\n",
    "print(f'AM1 has been successfully finished on all clusters. You can view logs at \"{output_path}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 BP86 SVP General gradient approximation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify BP86 method\n",
    "method = '!BP86 def2-SVP TightSCF Opt'\n",
    "\n",
    "# input directory of .pdb representatives\n",
    "input_dir = 'am1/output/'\n",
    "\n",
    "# output directory where converted .inp Orca \n",
    "# methods will be placed\n",
    "output_dir = 'bp86svp/input/'\n",
    "\n",
    "# number of CPUs to use\n",
    "nprocs = 12\n",
    "\n",
    "# specify spin (and charge)\n",
    "spin = 1\n",
    "# charge is specified in the first step \n",
    "# of 1. Molecule shape processing\n",
    "# charge = XXX\n",
    "\n",
    "\n",
    "for cluster in clusters:\n",
    "    infile = f'{input_dir}{cluster}/{cluster}.xyz'\n",
    "    outfile = f'{output_dir}{cluster}.inp'\n",
    "    \n",
    "    pdb2orca(infile, outfile, method, (charge,spin), nprocs=nprocs, xyz=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the BP86 General gradient approximation method\n",
    "\n",
    "input_path = 'bp86svp/input/'\n",
    "output_path = 'bp86svp/output/'\n",
    "\n",
    "\n",
    "for method_file in os.listdir(input_path):\n",
    "    if '.inp' in method_file:\n",
    "        log_file = method_file.replace('inp', 'out')\n",
    "        cluster_dir = method_file.replace('.inp', '/')\n",
    "        cluster_dir_path = output_path + cluster_dir\n",
    "\n",
    "        if not os.path.exists(cluster_dir_path):\n",
    "            os.mkdir(cluster_dir_path)    \n",
    "        shutil.copy(input_path + method_file, cluster_dir_path)\n",
    "\n",
    "        #temporary log !!!!!!!!!!!!!\n",
    "        orca_run(method_file, cluster_dir_path + log_file, workdir=cluster_dir_path, parallel=True)\n",
    "    \n",
    "parallel_wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check output && discard non-converging clusters\n",
    "number_of_clusters = len(clusters)\n",
    "\n",
    "for cluster in clusters:\n",
    "    log_file = f'{output_path}{cluster}/{cluster}.out'\n",
    "    with open(log_file) as infile:\n",
    "        log = infile.read()\n",
    "        if '****ORCA TERMINATED NORMALLY****' not in log:\n",
    "            !{orca_job_check} {log_file}\n",
    "            clusters.remove(cluster)\n",
    "\n",
    "print(f'''{len(clusters)}/{number_of_clusters} successfully converged - unconverged are not considered\n",
    "           in next steps.\\n You can view logs at \"{output_path}\" directory''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 BP86 TZVP General gradient approximation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify BP86 method\n",
    "method = '!BP86 def2-TZVP TightSCF Opt'\n",
    "\n",
    "# input directory of .pdb representatives\n",
    "input_dir = 'bp86svp/output/'\n",
    "\n",
    "# output directory where converted .inp Orca \n",
    "# methods will be placed\n",
    "output_dir = 'bp86tzvp/input/'\n",
    "\n",
    "# number of CPUs to use\n",
    "nprocs = 12\n",
    "\n",
    "# specify spin (and charge)\n",
    "spin = 1\n",
    "# charge is specified in the first step \n",
    "# of 1. Molecule shape processing\n",
    "# charge = XXX\n",
    "\n",
    "\n",
    "for cluster in clusters:\n",
    "    infile = f'{input_dir}{cluster}/{cluster}.xyz'\n",
    "    outfile = f'{output_dir}{cluster}.inp'\n",
    "    \n",
    "    pdb2orca(infile, outfile, method, (charge,spin), nprocs=nprocs, xyz=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the BP86 TZVP General gradient approximation method\n",
    "\n",
    "input_path = 'bp86tzvp/input/'\n",
    "output_path = 'bp86tzvp/output/'\n",
    "\n",
    "\n",
    "for method_file in os.listdir(input_path):\n",
    "    if '.inp' in method_file:\n",
    "        log_file = method_file.replace('inp', 'out')\n",
    "        cluster_dir = method_file.replace('.inp', '/')\n",
    "        cluster_dir_path = output_path + cluster_dir\n",
    "\n",
    "        if not os.path.exists(cluster_dir_path):\n",
    "            os.mkdir(cluster_dir_path)    \n",
    "        shutil.copy(input_path + method_file, cluster_dir_path)\n",
    "\n",
    "        #temporary log !!!!!!!!!!!!!\n",
    "        orca_run(method_file, cluster_dir_path + log_file, workdir=cluster_dir_path, parallel=True)\n",
    "    \n",
    "parallel_wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check output && discard non-converging clusters\n",
    "number_of_clusters = len(clusters)\n",
    "\n",
    "for cluster in clusters:\n",
    "    log_file = f'{output_path}{cluster}/{cluster}.out'\n",
    "    with open(log_file) as infile:\n",
    "        log = infile.read()\n",
    "        if '****ORCA TERMINATED NORMALLY****' not in log:\n",
    "            !{orca_job_check} {log_file}\n",
    "            clusters.remove(cluster)\n",
    "\n",
    "print(f'''{len(clusters)}/{number_of_clusters} successfully converged - unconverged are not considered\n",
    "           in next steps.\\n You can view logs at \"{output_path}\" directory''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract final energies from output of Orca TZVP method\n",
    "# note: energies are in hartree unit\n",
    "orca_energies = []\n",
    "\n",
    "for cluster in clusters:\n",
    "    with open(f'bp86tzvp/output/{cluster}/{cluster}.out') as infile:\n",
    "        for line in reversed(list(infile)):\n",
    "            energy_list = re.findall(r'(FINAL SINGLE POINT ENERGY)( +)(-?\\d+\\.\\d+)', line)\n",
    "            if len(energy_list) > 0:\n",
    "                orca_energies.append(float(energy_list[0][2]))\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from hartree to kJ/mol\n",
    "\n",
    "CONVERSION_CONST = 2625.499638\n",
    "min_energy = min(orca_energies)\n",
    "\n",
    "energies_in_kJ = []\n",
    "for energy in orca_energies:\n",
    "    energies_in_kJ.append((energy-min_energy)*CONVERSION_CONST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy atoms from conformation before QM and combine it with orca optimised conformations\n",
    "\n",
    "output_dir = \"pdb_opt/\"\n",
    "input_dir = \"bp86tzvp/output/outCluster\"\n",
    "\n",
    "\n",
    "atoms = []\n",
    "with open(\"clustering/outClustersPDB/outCluster0.pdb\", \"r\") as ifile:\n",
    "    for line in ifile.readlines():\n",
    "        if \"ATOM\" in line:\n",
    "            atoms.append(line[:26])\n",
    "\n",
    "for i in clusters_ids:\n",
    "    hetatms = []\n",
    "    !babel -ixyz {input_dir}{i}/outCluster{i}.xyz -opdb {output_dir}temp_cluster_{i}.pdb\n",
    "    with open(\"{}temp_cluster_{}.pdb\".format(output_dir, i), \"r\") as ifile:\n",
    "        for line in ifile.readlines():\n",
    "            if \"HETATM\" in line:\n",
    "                hetatms.append(line[27:66])\n",
    "    with open(\"pdb_opt/cluster{}.pdb\".format(i), \"w\") as output_cluster:\n",
    "        for j in range(len(atoms)):\n",
    "            output_cluster.write(atoms[j])\n",
    "            output_cluster.write(hetatms[j] + \"\\n\")\n",
    "\n",
    "!rm {output_dir}/temp_*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"pdb_opt/\"\n",
    "output_file = \"clusters.pdb\"\n",
    "\n",
    "#concatinate optimised conformations to trajectory\n",
    "with open(output_file, \"w\") as ofile:\n",
    "    for i in clusters_ids:\n",
    "        ofile.write(\"MODEL {}\\n\".format(str(i)))\n",
    "        with open(\"{}cluster{}.pdb\".format(input_dir, i), \"r\") as ifile:\n",
    "            ofile.write(ifile.read())\n",
    "            ofile.write(\"ENDMDL\\n\")\n",
    "\n",
    "with open(\"plumed.dat\", \"w\") as ifile:\n",
    "    cvs = []\n",
    "    num_atoms = sum(1 for line in open(\"{}cluster{}.pdb\".format(input_dir, clusters_ids[0])))\n",
    "    ifile.write(\"WHOLEMOLECULES ENTITY0=1-{}\\n\".format(str(num_atoms)))\n",
    "    for i in range(0, len(torsions)):\n",
    "        cvs.append(\"cv{}\".format(i))\n",
    "        ifile.write(\"TORSION ATOMS=\")\n",
    "        ifile.write(\",\".join(str(x) for x in torsions[i]))\n",
    "        ifile.write(\" LABEL={}\\n\".format(cvs[i]))\n",
    "    ifile.write(\"PRINT ARG=\")\n",
    "    ifile.write(\",\".join(cvs))\n",
    "    ifile.write(\" STRIDE=1 FILE=DIHEDRALS\")\n",
    "\n",
    "#compute dihedrals\n",
    "gmx_run(f\"driver --plumed plumed.dat --mf_pdb {output_file}\")\n",
    "\n",
    "lines = []\n",
    "with open(\"DIHEDRALS\", \"r\") as ifile:\n",
    "    for line in ifile.readlines():\n",
    "        if \"#\" not in line:\n",
    "            lines.append(line)\n",
    "with open(\"DIHEDRALS\", \"w\") as ofile:\n",
    "    for line in lines:\n",
    "        ofile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform minimisations and compute GAFF energy\n",
    "\n",
    "cvs = [[] for _ in range(len(clusters_ids))]\n",
    "with open(\"DIHEDRALS\",\"r\") as ifile:\n",
    "    dihedrals = ifile.readlines()\n",
    "    for i in range(len(dihedrals)):\n",
    "        t_angles = dihedrals[i].split()\n",
    "        for j in range(len(torsions)):\n",
    "            cvs[i].append(float(t_angles[j+1])*(180/math.pi))\n",
    "\n",
    "def generate_restraint(cluster_i):\n",
    "    with open(\"MOL_GMX.top\", \"r\") as ifile, open(\"gaff/cluster_{}/restrained.top\".format(str(cluster_i)), \"w\") as ofile:\n",
    "        for line in ifile.readlines():\n",
    "            if line == \"; Ligand position restraints\\n\":\n",
    "                ofile.write(\"\\n\")\n",
    "                ofile.write(\"[ dihedral_restraints ]\\n\")\n",
    "                for j in range(len(torsions)):\n",
    "                    ofile.write(\" \".join(torsions[j]))\n",
    "                    ofile.write(\"2 %3.1f 0 500\\n\" %cvs[i][j])\n",
    "            ofile.write(line)\n",
    "\n",
    "#select groups for energy evaluation\n",
    "groups = \"10\"\n",
    "\n",
    "for i in tqdm(clusters_ids):\n",
    "    !mkdir -p -m 757 gaff/cluster_{i}\n",
    "    shutil.copy(\"pdb_opt/cluster{}.pdb\".format(i), \"gaff/cluster_{}\".format(i))\n",
    "    shutil.copy(\"MOL_GMX.top\", \"gaff/cluster_{}\".format(i))\n",
    "    shutil.copy(\"em.mdp\", \"gaff/cluster_{}\".format(i))\n",
    "    shutil.copy(\"md.mdp\", \"gaff/cluster_{}\".format(i))\n",
    "    generate_restraint(i)\n",
    "    gmx_run(f\"editconf -f cluster{i}.pdb -box 3 3 3 -bt cubic -c -o box.gro\", workdir=f\"/gaff/cluster_{i}\")\n",
    "    gmx_run(\"grompp -f em -c box.gro -p restrained.top -o em1\", workdir=f\"/gaff/cluster_{i}\")\n",
    "    gmx_run(\"mdrun -ntomp 2 -s em1 -c after_em1 -g em1 -e em1 -o em1\", workdir=f\"/gaff/cluster_{i}\")\n",
    "    gmx_run(\"grompp -f md -c box.gro -p MOL_GMX.top -o rerun\", workdir=f\"/gaff/cluster_{i}\")\n",
    "    gmx_run(\"mdrun -ntomp 2 -s rerun -rerun em1 -c after_rerun -g rerun -e rerun -o rerun\", workdir=f\"/gaff/cluster_{i}\")\n",
    "    gmx_run(\"energy -f rerun.edr -o rerun.xvg\", workdir=f\"/gaff/cluster_{i}\", groups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract energies and from each energy value subtract minimal energy\n",
    "\n",
    "energies_lst = []\n",
    "\n",
    "for i in clusters_ids:\n",
    "    with open(\"gaff/cluster_{}/rerun.xvg\".format(i, \"r\")) as ifile:\n",
    "        last_line = ifile.readlines()[-1]\n",
    "        energies = last_line.split(\" \")\n",
    "        energies_lst.append(energies[len(energies) - 1].rstrip())\n",
    "\n",
    "min_energy = min(energies_lst)\n",
    "with open(\"gaff_energies.txt\", \"w\") as ofile:\n",
    "    for energy in energies_lst:\n",
    "        ofile.write(\"{} \\n\".format((float(energy) - float(min_energy))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define correction of force field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subtract from orca energies computed in step 5, GAFF energies computed in step 6\n",
    "\n",
    "with open(\"reference\", \"w\") as ofile:\n",
    "    with open(\"orca_energies.txt\", \"r\") as orca_energies, open(\"gaff_energies.txt\", \"r\") as gaff_energies:\n",
    "        for orca_energy in orca_energies.readlines():\n",
    "            for gaff_energy in gaff_energies.readlines():\n",
    "                ofile.write(\"{} \\n\".format((float(orca_energy) - float(gaff_energy))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write final corrections into output file along with representative conformations\n",
    "\n",
    "input_dir = \"pdb_opt/\"\n",
    "\n",
    "with open(\"reference.pdb\", \"w\") as ofile, open(\"reference\", \"r\") as ifile:\n",
    "    final_energies = ifile.readlines()\n",
    "    energy_index = 0\n",
    "    for i in clusters_ids:\n",
    "        ofile.write(\"REMARK X={}\".format(final_energies[energy_index]))\n",
    "        with open(\"{}cluster{}.pdb\".format(input_dir, i), \"r\") as ifile1:\n",
    "            ofile.writelines(ifile1.readlines())\n",
    "        energy_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = []\n",
    "y1 = []\n",
    "\n",
    "with open(\"DIHEDRALS\") as ifile:\n",
    "    for line in ifile.readlines():\n",
    "        split_values = line.split()\n",
    "        x1.append(split_values[1])\n",
    "        y1.append(split_values[2])\n",
    "\n",
    "plot_landmarks(x, y, x1, y1).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
