{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Property Map Collective Variable Force Field Correction Pipeline\n",
    "---\n",
    "The pipeline generates force field corrections in .pdb format and is divided into these steps:\n",
    "\n",
    "1. [Molecule shape processing](#1.-Molecule-shape-processing)\n",
    "2. [Preparation of environment and molecule](#2.-Preparation-of-environment-and-molecule)\n",
    "3. [Generation of representative configurations](#3.-Generation-of-representative-configurations)\n",
    "4. [Accurate energy computation](#4.-Accurate-energy-computation)\n",
    "5. [Inaccurate energy computation](#5.-Inaccurate-energy-computation)\n",
    "6. [Define correction of force field](#6.-Define-correction-of-force-field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "# import chemical software\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit import Chem\n",
    "from tqdm.notebook import tqdm\n",
    "from molvs import Standardizer\n",
    "import nglview as nv\n",
    "import pytraj as pt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import custom libraries\n",
    "from modules.draw_3d import drawit\n",
    "from modules.convert import convert_to_orca_methods\n",
    "from modules.plot_graph import plot_landmarks\n",
    "from modules.k8s.k8s_run import gmx_run, orca_run, parmtsnecv_run, parallel_wait\n",
    "\n",
    "# path to needed scripts\n",
    "orca_job_check = '/home/base/modules/orcajobcheck.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Molecule shape processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify input of desired molecule in SMILES\n",
    "smiles_molecule = 'CC1=C(C=C(C=C1)NC(=O)C2=CC=C(C=C2)C[NH+]3CCN(CC3)C)NC4=NC=CC(=N4)C5=CN=CC=C5'\n",
    "\n",
    "# set visualization parameters\n",
    "# ... add Indices to molecule image\n",
    "IPythonConsole.drawOptions.addAtomIndices = True\n",
    "\n",
    "# ... set molecule size\n",
    "IPythonConsole.molSize = 900,900\n",
    "\n",
    "\n",
    "molecule = Chem.MolFromSmiles(smiles_molecule)\n",
    "molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Standardizer()\n",
    "molecule = s.standardize(molecule)\n",
    "molecule = Chem.AddHs(molecule)\n",
    "natoms = molecule.GetNumAtoms()\n",
    "charge = Chem.rdmolops.GetFormalCharge(molecule)\n",
    "\n",
    "molecule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Set the lowest energy configuration\n",
    "Perform basic energy minimisation by running [Merck molecular force field (MMFF94)](https://open-babel.readthedocs.io/en/latest/Forcefields/mmff94.html) and choose the conformation with the lowest energy.\n",
    "\n",
    "Visualize the configuration with lowest energy in 3D afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of configurations to generate\n",
    "numc = 50\n",
    "\n",
    "Chem.AllChem.EmbedMultipleConfs(molecule, clearConfs=True, numConfs=numc)\n",
    "\n",
    "# run MMFF94\n",
    "optim = Chem.AllChem.MMFFOptimizeMoleculeConfs(molecule)\n",
    "\n",
    "minid = -1\n",
    "minene = sys.float_info.max\n",
    "for i in range(len(optim)):\n",
    "    if optim[i][1] < minene:\n",
    "        minene = optim[i][1]\n",
    "        minid = i\n",
    "\n",
    "# write to file molekula.mol for further processing\n",
    "writer = Chem.SDWriter('molekula.mol')\n",
    "writer.write(molecule, confId = minid)\n",
    "\n",
    "drawit(molecule, confId = minid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Detect torsion angles\n",
    "Detect torsions based on pattern in *smarts*. Output can be checked on 2D visualization in step [2. Molecule shape processing](#2.-Molecule-shape-processing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_smarts = ''.join(('[!$([NH]!@C(=O))&!D1&!$(*#*)&!$([C;H3])&!$([O;H1])&!$([N;H3])]-&!@',\n",
    "                       '[!$([NH]!@C(=O))&!D1&!$(*#*)&!$([C;H3])&!$([O;H1])&!$([N;H3])]'))\n",
    "\n",
    "rotatable_bond = Chem.MolFromSmarts(bond_smarts)\n",
    "rotatables = molecule.GetSubstructMatches(rotatable_bond)\n",
    "print(f'Rotatables: {rotatables}')\n",
    "\n",
    "\n",
    "torsions = []\n",
    "for rotatable in rotatables:\n",
    "    pairs1 = []\n",
    "    pairs2 = []\n",
    "    for bond in molecule.GetBonds():\n",
    "        if rotatable[0] == bond.GetBeginAtomIdx() and rotatable[1] != bond.GetEndAtomIdx():\n",
    "            pairs1.append([bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()])\n",
    "        if rotatable[1] == bond.GetBeginAtomIdx() and rotatable[0] != bond.GetEndAtomIdx():\n",
    "            pairs2.append([bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()])\n",
    "    torsions.append([pairs1[0][1], pairs1[0][0], pairs2[0][0], pairs2[0][1]])\n",
    "print(f'Torsions: {torsions}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparation of environment and molecule\n",
    "### 2.1 Perform energetic minimisation\n",
    "Generate config file and other files needed for energetic minimisation. During generation an ordering of atoms will get wrong. This is fixed afterwards from output files to fit the minimised molecule.\n",
    "\n",
    "Finally perform an energetic minimisation using [Gromacs](https://www.gromacs.org/). This pipeline uses wrapper so the Gromacs can be run independently to this environment. Please read the wrapper [documentation](https://github.com/CERIT-SC/pmcvff-correction/tree/jupyter-refactor/modules/k8s) before you interact with any Gromacs command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"em/em.mdp\", \"w\") as emfile:\n",
    "    lines = [\n",
    "        'integrator          =  steep',\n",
    "        'nsteps              =  100000',\n",
    "        'emtol               =  0',\n",
    "        'emstep              =  0.1',\n",
    "        'nstcomm             =  1',\n",
    "        'nstxout             =  100',\n",
    "        'nstvout             =  100',\n",
    "        'nstfout             =  0',\n",
    "        'nstlog              =  100',\n",
    "        'nstenergy           =  100',\n",
    "        'nstlist             =  1',\n",
    "        'ns_type             =  grid',\n",
    "        'coulombtype         =  cut-off',\n",
    "        'rlist               =  1.4',\n",
    "        'rcoulomb            =  1.4',\n",
    "        'rvdw                =  1.4',\n",
    "        'energygrps          =  System',\n",
    "        'epsilon-r           =  80'\n",
    "    ]\n",
    "    emfile.writelines(line + '\\n' for line in lines)\n",
    "    \n",
    "\n",
    "!antechamber -i molekula.mol -fi mdl -o molekula.prepi -fo prepi -c bcc -nc {charge} && \\\n",
    "parmchk2 -i molekula.prepi -f prepi -o molekula.frcmod && \\\n",
    "tleap -f tleapin.txt && \\\n",
    "acpype -p molekula.prmtop -x molekula.inpcrd\n",
    "\n",
    "shutil.copy(\"MOL.amb2gmx/MOL_GMX.gro\", \"em/\")\n",
    "shutil.copy(\"MOL.amb2gmx/MOL_GMX.top\", \"em/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix ordering of atoms\n",
    "\n",
    "order_before = []\n",
    "with open('sqm.pdb','r') as pdbfile:\n",
    "    for atom in pdbfile.readlines():\n",
    "        order_before.append(atom.split()[2])\n",
    "        \n",
    "order_after = []\n",
    "with open('MOL.amb2gmx/MOL_GMX.gro','r') as grofile:\n",
    "    for atom in grofile.readlines():\n",
    "        if atom.startswith('    1  MOL'):\n",
    "            order_after.append(atom.split()[2])\n",
    "\n",
    "            \n",
    "torsions_new = []\n",
    "torsion_new = []\n",
    "for torsion in torsions:\n",
    "    for i in torsion:       \n",
    "        torsion_new.append(order_after.index(order_before[i])+1)\n",
    "    torsions_new.append(torsion_new)\n",
    "    torsion_new = []\n",
    "    \n",
    "torsions = torsions_new\n",
    "print(f'New torsions: {torsions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmx_run('editconf -f MOL_GMX -o box -c -box 3 3 3', workdir='em')\n",
    "gmx_run('grompp -f em.mdp -c box -p MOL_GMX -o em1', workdir='em')\n",
    "gmx_run('mdrun -deffnm em1 -ntomp 2', workdir='em')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Perform molecular dynamics simulation\n",
    "Create config file and perform molecular dynamics simulation. Simulation trajectory can be visualized.\n",
    "\n",
    "Afterwards a [periodic boundary conditions](https://www.gromacs.org/Documentation_of_outdated_versions/Terminology/Periodic_Boundary_Conditions) must be applied so the molecule \"does not jump out of the box\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('md/md.mdp', 'w') as mdfile:\n",
    "    lines = [\n",
    "        'integrator          = sd',\n",
    "        'nsteps              = 100000',\n",
    "        'dt                  = 0.001',\n",
    "        'nstxout             = 1000',\n",
    "        'nstvout             = 1000',\n",
    "        'nstenergy           = 1000',\n",
    "        'nstlog              = 1000',\n",
    "        'continuation        = no',\n",
    "        'constraints         = none',\n",
    "        'cutoff-scheme       = Verlet',\n",
    "        'ns_type             = grid',\n",
    "        'nstlist             = 1',\n",
    "        'rlist               = 1.4',\n",
    "        'rcoulomb            = 1.4',\n",
    "        'rvdw                = 1.4',\n",
    "        'coulombtype         = cut-off',\n",
    "        'tcoupl              = V-rescale',\n",
    "        'tc-grps             = system',\n",
    "        'tau_t               = 0.1',\n",
    "        'ref_t               = 300',\n",
    "        'pcoupl              = no',\n",
    "        'pbc                 = xyz',\n",
    "        'gen_vel             = yes',\n",
    "        'epsilon-r           = 80'\n",
    "    ]\n",
    "    mdfile.writelines(line + '\\n' for line in lines)\n",
    "    \n",
    "shutil.copy('em/em1.gro', 'md/')\n",
    "shutil.copy('MOL.amb2gmx/MOL_GMX.top', 'md/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmx_run('grompp -f md.mdp -c em1 -p MOL_GMX -o md1', workdir='md')\n",
    "gmx_run('mdrun -deffnm md1 -ntomp 2', workdir='md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert trajectory to .pdb format so it can be visualized\n",
    "\n",
    "# select group for trjconv evaluation output\n",
    "# Group     0 (         System)\n",
    "# Group     1 (          Other)\n",
    "# Group     2 (            MOL)\n",
    "group = '0'\n",
    "\n",
    "\n",
    "gmx_run('trjconv -pbc nojump -s md1.tpr -f md1.trr -o outTraj.pdb', workdir='md', groups=group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the molecular dynamics trajectory\n",
    "traj = pt.load('md/outTraj.pdb')\n",
    "view = nv.show_pytraj(traj)\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix periodic boundaries errors \n",
    "\n",
    "# select group for trjconv evaluation output\n",
    "# Group     0 (         System)\n",
    "# Group     1 (          Other)\n",
    "# Group     2 (            MOL)\n",
    "group = '1'\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(torsions))):\n",
    "    fr = str(float(100-len(torsions)+i)-0.01)\n",
    "    to = str(float(100-len(torsions)+i)+0.01)\n",
    "    gmx_run(f'trjconv -pbc nojump -s md1 -f md1 -o frame{i}.gro -b {fr} -e {to}<<EOF\\n0\\nEOF',\n",
    "            workdir='md',\n",
    "            groups=group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generation of representative configurations\n",
    "### 3.1 Trajectory generation\n",
    "Create config file and *plumed.dat* file. Based on these files run the simulation (with metadynamics) to generate a trajectory.\n",
    "\n",
    "[Plumed](https://www.plumed.org/) is used to run metadynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mtd/mtd.mdp', 'w') as mtdfile:\n",
    "    lines = [\n",
    "        'integrator          = sd',\n",
    "        'nsteps              = 10000000',\n",
    "        'dt                  = 0.001',\n",
    "        'nstxout             = 10000',\n",
    "        'nstvout             = 10000',\n",
    "        'nstenergy           = 1000',\n",
    "        'nstlog              = 1000',\n",
    "        'continuation        = no',\n",
    "        'constraints         = none',\n",
    "        'cutoff-scheme       = Verlet',\n",
    "        'ns_type             = grid',\n",
    "        'nstlist             = 1',\n",
    "        'rlist               = 1.4',\n",
    "        'rcoulomb            = 1.4',\n",
    "        'rvdw                = 1.4',\n",
    "        'coulombtype         = cut-off',\n",
    "        'tcoupl              = V-rescale',\n",
    "        'tc-grps             = system',\n",
    "        'tau_t               = 0.1',\n",
    "        'ref_t               = 300',\n",
    "        'pcoupl              = no',\n",
    "        'pbc                 = xyz',\n",
    "        'gen_vel             = yes',\n",
    "        'epsilon-r           = 80'\n",
    "    ]\n",
    "    mtdfile.writelines(line + '\\n' for line in lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(torsions)):\n",
    "    if not os.path.exists(f'mtd/w{i}'):\n",
    "        os.mkdir(f'mtd/w{i}')\n",
    "        \n",
    "    with open(f'mtd/w{i}/plumed.dat', \"w\") as plumeddat:\n",
    "        plumeddat.write('RANDOM_EXCHANGES\\n' +\n",
    "                       f'WHOLEMOLECULES ENTITY0=1-{natoms}\\n')\n",
    "        for j in range(len(torsions)):\n",
    "            line = ','.join((f'TORSION ATOMS={torsions[j][0]},{torsions[j][1]}',\n",
    "                             f'{torsions[j][2]},{torsions[j][3]} LABEL=cv{j+1}\\n'))\n",
    "            plumeddat.write(line)\n",
    "        line = ' '.join((f'METAD ARG=cv{i+1} HEIGHT=0.5 SIGMA=0.3 PACE=1000 GRID_MIN=-pi',\n",
    "                         'GRID_MAX=pi BIASFACTOR=15 LABEL=be\\n'))\n",
    "        plumeddat.write(line)\n",
    "        cvs = \"\"\n",
    "        for j in range(len(torsions)):\n",
    "            cvs = cvs + f'cv{j+1},'\n",
    "        cvs = cvs[:-1]\n",
    "        plumeddat.write(f'PRINT ARG={cvs} STRIDE=1000 FILE=COLVAR\\n' +\n",
    "                         'PRINT ARG=be.bias STRIDE=1000 FILE=BIAS\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.copy('MOL.amb2gmx/MOL_GMX.top', 'mtd/')\n",
    "\n",
    "# perform preprocessing before generation of the trajectory\n",
    "for i in tqdm(range(len(torsions))):\n",
    "    shutil.copy(f'md/frame{i}.gro', f'mtd/w{i}/')\n",
    "    gmx_run(f'grompp -f mtd.mdp -c w{i}/frame{i} -p MOL_GMX -o w{i}/mtd1',\n",
    "            workdir='mtd',\n",
    "            parallel=True)\n",
    "parallel_wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = ''\n",
    "for i in range(len(torsions)):\n",
    "    directories = directories + f'w{i} '\n",
    "\n",
    "# see mdrunlog in mtd directory for insight into running \n",
    "# mdrun simulation (e.g 'tail -f mdrunlog')\n",
    "gmx_run(f'mdrun -g mdrunlog -ntomp 1 -deffnm mtd1 -replex 500 -plumed plumed.dat -multidir {directories}', \n",
    "        workdir='mtd', \n",
    "        mpi_run=len(torsions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Configurations clustering\n",
    "Concatinate all the trajectories that simulation produced. Then cluster this trajectory to groups for which one representative configuration is chosen (*cutoff* can be modified for more/less clusters).\n",
    "\n",
    "Result of [Gromacs clustering](https://manual.gromacs.org/documentation/current/onlinehelp/gmx-cluster.html) is .pdb file containing all representative configurations. These must be divided into separate .pdb files for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories = ''\n",
    "for i in range(len(torsions)):\n",
    "    trajectories = trajectories + f'mtd/w{i}/mtd1.trr '\n",
    "\n",
    "# concatinate trajectories    \n",
    "gmx_run(f'trjcat -f {trajectories} -cat -o mtd/mtd1.trr')\n",
    "\n",
    "# make index file with non-hydrogen atoms\n",
    "gmx_run(\"make_ndx -f md/md1.tpr -o mtd/index.ndx\", make_ndx=\"1&!aH*\")\n",
    "\n",
    "\n",
    "# select groups for cluster evaluation output\n",
    "# Group     0 (         System)\n",
    "# Group     1 (          Other)\n",
    "# Group     2 (            MOL)\n",
    "# Group     3 (         Custom)\n",
    "groups = '30'\n",
    "\n",
    "gmx_run('''cluster -method gromos -f mtd/mtd1.trr -s mtd/w0/mtd1.tpr -n mtd/index.ndx -cutoff 0.15 \\\n",
    "           -cl clustering/outClusters.pdb''', groups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide all clusters from clustering output file \n",
    "# to single files and index them from 0.\n",
    "# Also fix missing element of each ATOM on \n",
    "# line 77 (by pdb format specification)\n",
    "cluster_index = 0\n",
    "i = 0\n",
    "\n",
    "with open('clustering/outClusters.pdb') as infile:\n",
    "    clusters = infile.readlines()\n",
    "    while i < len(clusters):\n",
    "        with open(f'clustering/outClustersPDB/outCluster{cluster_index}.pdb', 'w') as outfile:\n",
    "            for line in clusters[i:]:\n",
    "                split_line = line.split()\n",
    "                if split_line[0] == 'ATOM':\n",
    "                    line = line[:77] + split_line[2][0] + '\\n'\n",
    "                outfile.write(line)\n",
    "                i += 1\n",
    "                if line == 'ENDMDL\\n':\n",
    "                    break\n",
    "            cluster_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Visualize landmarks\n",
    "Goal of this part is to compute embeddings which are visualized afterwards. Each step is performed on the trajectory which results from previous step. Base trajectory used in 1st step is the concatinated trajectory from metadynamics simulation.\n",
    "\n",
    "1. Apply periodic boundary conditions to metadynamics trajectory\n",
    "2. Perform fitting on the trajectory\n",
    "3. Remove Hydrogen\n",
    "4. Train [parmtSNEcv](https://gitlab.ics.muni.cz/spiwokv/parmtSNEcv)\n",
    "5. Compute embeddings\n",
    "\n",
    "Finally visualize all generated configurations from metadynamics trajectory in contrast to representative clusters configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group     0 (         System)\n",
    "# Group     1 (          Other)\n",
    "# Group     2 (            MOL)\n",
    "# Group     3 (         Custom)\n",
    "# select group for periodic boundaries check output:\n",
    "group = '0'\n",
    "gmx_run('trjconv -f mtd/mtd1.trr -s mtd/w0/mtd1.tpr -pbc mol -o visualization/traj/mtd1_nopbc.xtc', groups=group)\n",
    "\n",
    "# select groups for fitting and output:\n",
    "groups = '00'\n",
    "gmx_run('''trjconv -f visualization/traj/mtd1_nopbc.xtc -s clustering/outClustersPDB/outCluster0.pdb \\\n",
    "           -fit rot+trans -o visualization/traj/mtd1_fit.xtc''', groups=groups)\n",
    "\n",
    "# select group for no Hydrogen output:\n",
    "group = '3'\n",
    "gmx_run('trjconv -f visualization/traj/mtd1_fit.xtc -n mtd/index.ndx -o visualization/traj/mtd1_fit_noH.xtc',\n",
    "        groups=group)\n",
    "\n",
    "# select groups for size of the box and output:\n",
    "groups = '33'\n",
    "gmx_run('''editconf -f clustering/outClustersPDB/outCluster0.pdb -n mtd/index.ndx -box 3 3 3 -c \\\n",
    "           -o visualization/ref.pdb''', groups=groups)\n",
    "\n",
    "# fix weights of atoms\n",
    "data = ''\n",
    "with open('visualization/ref.pdb', 'r') as infile:\n",
    "    data = infile.read()\n",
    "    data = data.replace('0.00', '1.00')\n",
    "with open('visualization/ref.pdb', 'w') as outfile:\n",
    "    outfile.writelines(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train parmtSNEcv\n",
    "parmtsnecv_run('''parmtSNEcv -i traj/mtd1_fit_noH.xtc -p ref.pdb -boxx 3 -boxy 3 -boxz 3 \\\n",
    "               -dim 2 -layers 2 -o out.txt -plumed plumed.dat -epochs 2000''', workdir='visualization')\n",
    "\n",
    "# modify plumed.dat to compute embedding in every step (100->1) \n",
    "# and change the name of file for *** mtd trajectory ***\n",
    "with open('visualization/plumed.dat', 'r') as infile:\n",
    "    data = infile.read()\n",
    "    data = data.replace('STRIDE=100', 'STRIDE=1')\n",
    "    data = data.replace('COLVAR', '2d_embedding')\n",
    "with open('visualization/plumed.dat', 'w') as outfile:\n",
    "    outfile.writelines(data)\n",
    "\n",
    "# run with plumed\n",
    "gmx_run('driver --plumed plumed.dat --mf_xtc traj/mtd1_fit.xtc', workdir='visualization')\n",
    "\n",
    "# modify plumed.dat to compute embedding in every step and change name of file for *** representatives ***\n",
    "with open('visualization/plumed.dat', 'r') as infile:\n",
    "    data = infile.read()\n",
    "    data = data.replace('2d_embedding', 'landmarks')\n",
    "with open('visualization/plumed.dat', 'w') as outfile:\n",
    "    outfile.writelines(data)\n",
    "\n",
    "# run with plumed\n",
    "shutil.copy('clustering/outClusters.pdb', 'visualization/')\n",
    "gmx_run('driver --plumed plumed.dat --mf_pdb outClusters.pdb', workdir='visualization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize configurations in contrast to representative configurations\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "x1 = []\n",
    "y1 = []\n",
    "with open(\"visualization/2d_embedding\", \"r\") as infile:\n",
    "    for line in infile.readlines()[1:]:\n",
    "        split_values = line.split()\n",
    "        x.append(float(split_values[1]))\n",
    "        y.append(float(split_values[2]))\n",
    "with open(\"visualization/landmarks\", \"r\") as infile:\n",
    "    for line in infile.readlines()[1:]:\n",
    "        split_values = line.split()\n",
    "        x1.append(float(split_values[1]))\n",
    "        y1.append(float(split_values[2]))\n",
    "        \n",
    "        \n",
    "plt.figure(figsize=(100, 50), dpi=100)\n",
    "plt.scatter(x, y, c='b', marker='.', label='All Configurations', s=2000)\n",
    "plt.scatter(x1, y1, c='r', marker='o', label='Representative configurations', s=3000)\n",
    "plt.legend(loc='upper left', prop={'size': 80})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Accurate energy computation\n",
    "**Accurate energy** values are computed in this step using the [Orca](https://sites.google.com/site/orcainputlibrary/) quantum chemistry software. Orca uses [method files](https://sites.google.com/site/orcainputlibrary/generalinput) in exact format to perform the computations. Computation of exact energy values of each representative is composed of 3-step chain. Input for *AM1* are representative configurations defined by clustering in previous step. Each next computation is performed on the output of the previous step.\n",
    "\n",
    "1. **AM1 optimisation** (*input*: clustering results)\n",
    "2. **BP86 SVP** (*input*: AM1 output)\n",
    "3. **BP86 TZVP** (*input*: BP86 SVP output, *output*: exact energy values of representative configurations)\n",
    "\n",
    "Also each step above consists of 3 substeps:\n",
    "\n",
    "1. Convert the output of previous step to Orca compatible *.inp method*\n",
    "2. Perform Orca computation\n",
    "3. Analyse output (see logs)\n",
    "\n",
    "You can view the current state of Orca calculation in output logs (3rd substep) with for example *\\\"tail -f XXX\\\"* command. Please read the wrapper [documentation](https://github.com/CERIT-SC/pmcvff-correction/tree/jupyter-refactor/modules/k8s) before interacting with any Orca command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix indexing of atoms because Orca indexes from zero \n",
    "orca_torsions = [[] for _ in range(len(torsions))]\n",
    "torsion_index = 0\n",
    "for torsion in torsions:\n",
    "    for atom_index in torsion:\n",
    "        orca_torsions[torsion_index].append(atom_index - 1)\n",
    "    torsion_index += 1\n",
    "torsions = orca_torsions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a list of all clusters that are considered\n",
    "# in the quantum chemistry computations. For example\n",
    "# non-converged simulation on cluster will result in\n",
    "# discarding that cluster from further computations\n",
    "#\n",
    "# ** don't forget to reset clusters variable when\n",
    "# rerunning computations as non-converged will be\n",
    "# missing **\n",
    "clusters = []\n",
    "for cluster in os.listdir('clustering/outClustersPDB'):\n",
    "    if '.pdb' in cluster:\n",
    "        clusters.append(cluster.replace('.pdb', ''))\n",
    "        \n",
    "\n",
    "# convert .pdb file to orca method\n",
    "# - method specifies which method to apply by Orca\n",
    "# - info is to specify the *charge* and *spin* of molecule\n",
    "# - nprocs is to specify the number of CPU's to use (None for default)\n",
    "# - xyz specify True to convert .xyz to orca instead\n",
    "def pdb2orca(pdb_in, orca_out, method, info, nprocs=None, xyz=False):\n",
    "    with open(pdb_in, 'r') as infile, open(orca_out, 'w') as outfile:\n",
    "        outfile.write(f'{method}\\n')\n",
    "        \n",
    "        if nprocs:\n",
    "            outfile.write(f'%pal\\n' +\n",
    "                          f'nprocs {str(nprocs)}\\n' +\n",
    "                          f'end\\n')\n",
    "            \n",
    "        outfile.write('%geom\\n' +\n",
    "                      'Constraints\\n')\n",
    "        \n",
    "        # write torsions\n",
    "        for torsions_list in torsions:\n",
    "            outfile.write('{D ' +\n",
    "                          ' '.join(str(x) for x in torsions_list) +\n",
    "                          'C}\\n')\n",
    "        \n",
    "        outfile.write('end\\n' + \n",
    "                      'end\\n\\n' +\n",
    "                     f'*xyz {info[0]} {info[1]}\\n')\n",
    "        \n",
    "        # copy atom information from input and modify\n",
    "        # to fit the orca method format\n",
    "        if xyz:\n",
    "            for line in infile.readlines()[2:]:\n",
    "                outfile.write(f'{line}')\n",
    "        else:\n",
    "            for line in infile.readlines():\n",
    "                splitline = line.split()\n",
    "                if splitline[0] == 'ATOM':\n",
    "                    orca_line = f'{splitline[10]}       {splitline[5]}      {splitline[6]}       {splitline[7]}\\n'\n",
    "                    outfile.write(orca_line)\n",
    "                \n",
    "        outfile.write('*\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 AM1 geometry optimisation method\n",
    "Perform the semi-empirical [Austin Model 1](https://en.wikipedia.org/wiki/Austin_Model_1) method on representatives. It can be understood as kind of preprocessing (optimisation) which uses approximations instead of exact calculations to speed up the process of the next simulation. Output of AM1 is input for the next [BP86 SVP method.](###-4.3-BP86-SVP-method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the representatives from clustering to fit \n",
    "# the AM1 Orca method\n",
    "\n",
    "# specify AM1 method\n",
    "method = '!AM1 Opt'\n",
    "\n",
    "# input directory of .pdb representatives\n",
    "input_dir = 'clustering/outClustersPDB/'\n",
    "\n",
    "# output directory where converted .inp Orca \n",
    "# methods will be placed\n",
    "output_dir = 'am1/input/'\n",
    "\n",
    "# specify spin (and charge)\n",
    "spin = 1\n",
    "# charge is specified in the first step \n",
    "# of 1. Molecule shape processing\n",
    "# charge = XXX\n",
    "\n",
    "\n",
    "for pdb in tqdm(os.listdir(input_dir)):\n",
    "    if '.pdb' in pdb:\n",
    "        infile = input_dir + pdb\n",
    "        outfile = output_dir + pdb.replace('pdb', 'inp')\n",
    "\n",
    "        pdb2orca(infile, outfile, method, (charge,spin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the AM1 method optimisation\n",
    "\n",
    "input_path = \"am1/input/\"\n",
    "output_path = \"am1/output/\"\n",
    "\n",
    "\n",
    "for method_file in os.listdir(input_path):\n",
    "    if '.inp' in method_file:\n",
    "        log_file = method_file.replace('inp', 'out')\n",
    "        cluster_dir = method_file.replace('.inp', '/')\n",
    "        cluster_dir_path = output_path + cluster_dir\n",
    "\n",
    "        if not os.path.exists(cluster_dir_path):\n",
    "            os.mkdir(cluster_dir_path)    \n",
    "        shutil.copy(input_path + method_file, cluster_dir_path)\n",
    "\n",
    "        orca_run(method_file, cluster_dir_path + log_file, workdir=cluster_dir_path, parallel=True)\n",
    "    \n",
    "parallel_wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the output of AM1 optimisation\n",
    "\n",
    "for cluster in clusters:\n",
    "    with open(f'{output_path}{cluster}/{cluster}.out') as infile:\n",
    "        orca_log = infile.read()\n",
    "        if '****ORCA TERMINATED NORMALLY****' not in orca_log:\n",
    "            print(orca_log)\n",
    "            raise SystemExit(f'Error in AM1 method of {cluster}. You should not continue computation!')\n",
    "print(f'AM1 has been successfully finished on all clusters. You can view logs at \"{output_path}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 BP86 SVP General gradient approximation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify BP86 method\n",
    "method = '!BP86 def2-SVP TightSCF Opt'\n",
    "\n",
    "# input directory of .pdb representatives\n",
    "input_dir = 'am1/output/'\n",
    "\n",
    "# output directory where converted .inp Orca \n",
    "# methods will be placed\n",
    "output_dir = 'bp86svp/input/'\n",
    "\n",
    "# number of CPUs to use\n",
    "nprocs = 12\n",
    "\n",
    "# specify spin (and charge)\n",
    "spin = 1\n",
    "# charge is specified in the first step \n",
    "# of 1. Molecule shape processing\n",
    "# charge = XXX\n",
    "\n",
    "\n",
    "for cluster in clusters:\n",
    "    infile = f'{input_dir}{cluster}/{cluster}.xyz'\n",
    "    outfile = f'{output_dir}{cluster}.inp'\n",
    "    \n",
    "    pdb2orca(infile, outfile, method, (charge,spin), nprocs=nprocs, xyz=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the BP86 General gradient approximation method\n",
    "\n",
    "input_path = 'bp86svp/input/'\n",
    "output_path = 'bp86svp/output/'\n",
    "\n",
    "\n",
    "for method_file in os.listdir(input_path):\n",
    "    if '.inp' in method_file:\n",
    "        log_file = method_file.replace('inp', 'out')\n",
    "        cluster_dir = method_file.replace('.inp', '/')\n",
    "        cluster_dir_path = output_path + cluster_dir\n",
    "\n",
    "        if not os.path.exists(cluster_dir_path):\n",
    "            os.mkdir(cluster_dir_path)    \n",
    "        shutil.copy(input_path + method_file, cluster_dir_path)\n",
    "\n",
    "        orca_run(method_file, cluster_dir_path + log_file, workdir=cluster_dir_path, parallel=True)\n",
    "    \n",
    "parallel_wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check output && discard non-converging clusters\n",
    "number_of_clusters = len(clusters)\n",
    "\n",
    "for cluster in clusters:\n",
    "    log_file = f'{output_path}{cluster}/{cluster}.out'\n",
    "    with open(log_file) as infile:\n",
    "        log = infile.read()\n",
    "        if '****ORCA TERMINATED NORMALLY****' not in log:\n",
    "            !{orca_job_check} {log_file}\n",
    "            clusters.remove(cluster)\n",
    "\n",
    "print(f'''{len(clusters)}/{number_of_clusters} successfully converged - unconverged are not considered\n",
    "           in next steps.\\n You can view logs at \"{output_path}\" directory''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 BP86 TZVP General gradient approximation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify BP86 method\n",
    "method = '!BP86 def2-TZVP TightSCF Opt'\n",
    "\n",
    "# input directory of .pdb representatives\n",
    "input_dir = 'bp86svp/output/'\n",
    "\n",
    "# output directory where converted .inp Orca \n",
    "# methods will be placed\n",
    "output_dir = 'bp86tzvp/input/'\n",
    "\n",
    "# number of CPUs to use\n",
    "nprocs = 12\n",
    "\n",
    "# specify spin (and charge)\n",
    "spin = 1\n",
    "# charge is specified in the first step \n",
    "# of 1. Molecule shape processing\n",
    "# charge = XXX\n",
    "\n",
    "\n",
    "for cluster in clusters:\n",
    "    infile = f'{input_dir}{cluster}/{cluster}.xyz'\n",
    "    outfile = f'{output_dir}{cluster}.inp'\n",
    "    \n",
    "    pdb2orca(infile, outfile, method, (charge,spin), nprocs=nprocs, xyz=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the BP86 TZVP General gradient approximation method\n",
    "\n",
    "input_path = 'bp86tzvp/input/'\n",
    "output_path = 'bp86tzvp/output/'\n",
    "\n",
    "\n",
    "for method_file in os.listdir(input_path):\n",
    "    if '.inp' in method_file:\n",
    "        log_file = method_file.replace('inp', 'out')\n",
    "        cluster_dir = method_file.replace('.inp', '/')\n",
    "        cluster_dir_path = output_path + cluster_dir\n",
    "\n",
    "        if not os.path.exists(cluster_dir_path):\n",
    "            os.mkdir(cluster_dir_path)    \n",
    "        shutil.copy(input_path + method_file, cluster_dir_path)\n",
    "\n",
    "        orca_run(method_file, cluster_dir_path + log_file, workdir=cluster_dir_path, parallel=True)\n",
    "    \n",
    "parallel_wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check output && discard non-converging clusters\n",
    "number_of_clusters = len(clusters)\n",
    "\n",
    "for cluster in clusters:\n",
    "    log_file = f'{output_path}{cluster}/{cluster}.out'\n",
    "    with open(log_file) as infile:\n",
    "        log = infile.read()\n",
    "        if '****ORCA TERMINATED NORMALLY****' not in log:\n",
    "            !{orca_job_check} {log_file}\n",
    "            clusters.remove(cluster)\n",
    "\n",
    "print(f'''{len(clusters)}/{number_of_clusters} successfully converged - unconverged are not considered\n",
    "           in next steps.\\n You can view logs at \"{output_path}\" directory''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract final energies from output of Orca TZVP method\n",
    "# note: energies are in hartree unit\n",
    "orca_energies = {}\n",
    "\n",
    "for cluster in clusters:\n",
    "    with open(f'bp86tzvp/output/{cluster}/{cluster}.out') as infile:\n",
    "        for line in reversed(list(infile)):\n",
    "            energy_list = re.findall(r'(FINAL SINGLE POINT ENERGY)( +)(-?\\d+\\.\\d+)', line)\n",
    "            if len(energy_list) > 0:\n",
    "                orca_energies[cluster] = float(energy_list[0][2])\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from hartree to kJ/mol\n",
    "\n",
    "CONVERSION_CONST = 2625.499638\n",
    "min_energy = min(list(orca_energies.values()))\n",
    "\n",
    "for cluster, energy in orca_energies.items():\n",
    "    orca_energies[cluster] = (energy-min_energy)*CONVERSION_CONST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inaccurate energy computation\n",
    "**Inaccurate energy** values are computed via Gromacs. To compute energy values we use structures whose geometry was optimised by Orca. Afterwards dihedrals are computed from optimised structures' trajectory by [Plumed](https://www.plumed.org/). Finally using dihedrals compute inaccurate energy values.\n",
    "\n",
    "### 5.1 Convert optimised .xyz files to .pdb format\n",
    "Convert optimised structures to corresponding *.pdb* files by combining information about atoms from cluster representative *.pdb* file and xyz coordinates from optimised *.xyz* file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'bp86tzvp/output/'\n",
    "output_dir = 'pdb_opt/'\n",
    "\n",
    "\n",
    "# get information about atoms from cluster representative\n",
    "# (frist 26 columns - see .pdb format details for details)\n",
    "atoms = []\n",
    "with open('clustering/outClustersPDB/outCluster0.pdb', 'r') as infile:\n",
    "    for line in infile.readlines():\n",
    "            if \"ATOM\" in line:\n",
    "                atoms.append(line[:26])\n",
    "\n",
    "                \n",
    "# combine atoms from .pdb with optimised coordinates from .xyz\n",
    "for cluster in clusters:\n",
    "    with open(f'{input_dir}{cluster}/{cluster}.xyz', 'r') as infile, \\\n",
    "         open(f'{output_dir}{cluster}_opt.pdb', 'w') as outfile:\n",
    "        xyz = infile.readlines()[2:]\n",
    "        for i in range(len(atoms)):\n",
    "            split_line = xyz[i].split()\n",
    "            \n",
    "            # fix spaces near numbers with '-' to fit .pdb format\n",
    "            # and print only 3 decimal places\n",
    "            for j in range(1, len(split_line)):\n",
    "                split_line[j] = f'{round(float(split_line[j]), 3):.3f}'\n",
    "                if split_line[j][0] != '-':\n",
    "                    split_line[j] = f' {split_line[j]}'\n",
    "            pdb_line = f'{atoms[i]}     {split_line[1]}  {split_line[2]}  {split_line[3]}  1.00  0.00\\n'\n",
    "            outfile.write(pdb_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Compute dihedrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatinate optimised structures to a trajectory\n",
    "# so it can be processed by Plumed\n",
    "with open('clusters_opt.pdb', 'w') as outfile:\n",
    "    for cluster in clusters:\n",
    "        outfile.write(f'MODEL {cluster[len(cluster)-1]}\\n')\n",
    "        with open(f'pdb_opt/{cluster}_opt.pdb', 'r') as infile:\n",
    "            outfile.write(infile.read())\n",
    "            outfile.write('ENDMDL\\n')\n",
    "\n",
    "\n",
    "# create plumed file for Plumed processing\n",
    "with open('plumed.dat', 'w') as infile:\n",
    "    cvs = []\n",
    "    infile.write(f'WHOLEMOLECULES ENTITY0=1-{str(natoms)}\\n')\n",
    "    for i in range(0, len(torsions)):\n",
    "        cvs.append(f'cv{i}')\n",
    "        delimeted_torsions = ','.join(str(x) for x in torsions[i])\n",
    "        infile.write(f'TORSION ATOMS={delimeted_torsions} LABEL={cvs[i]}\\n')\n",
    "    cvs = ','.join(cvs)\n",
    "    infile.write(f'PRINT ARG={cvs} STRIDE=1 FILE=DIHEDRALS')\n",
    "    \n",
    "\n",
    "# compute dihedrals (produces output file DIHEDRALS)\n",
    "gmx_run(f'driver --plumed plumed.dat --mf_pdb clusters_opt.pdb')\n",
    "\n",
    "\n",
    "# remove all # lines, keep only numbers\n",
    "lines = []\n",
    "with open(\"DIHEDRALS\", \"r\") as ifile:\n",
    "    for line in ifile.readlines():\n",
    "        if \"#\" not in line:\n",
    "            lines.append(line)\n",
    "with open(\"DIHEDRALS\", \"w\") as ofile:\n",
    "    for line in lines:\n",
    "        ofile.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Compute inaccurate energy values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs = [[] for _ in range(len(clusters))]\n",
    "with open('DIHEDRALS','r') as infile:\n",
    "    dihedrals = infile.readlines()\n",
    "    for i in range(len(dihedrals)):\n",
    "        t_angles = dihedrals[i].split()\n",
    "        for j in range(len(torsions)):\n",
    "            cvs[i].append(float(t_angles[j+1])*(180/math.pi))\n",
    "\n",
    "            \n",
    "def generate_restraint(cluster):\n",
    "    with open('MOL.amb2gmx/MOL_GMX.top', 'r') as infile, \\\n",
    "         open(f'gaff/{cluster}/restrained.top', \"w\") as outfile:\n",
    "        for line in infile.readlines():\n",
    "            if line == \"; Ligand position restraints\\n\":\n",
    "                outfile.write(\"\\n\")\n",
    "                outfile.write(\"[ dihedral_restraints ]\\n\")\n",
    "                for j in range(len(torsions)):\n",
    "                    outfile.write(\" \".join(torsions[j]))\n",
    "                    outfile.write(\"2 %3.1f 0 500\\n\" %cvs[i][j])\n",
    "            outfile.write(line)\n",
    "\n",
    "            \n",
    "# select groups for energy evaluation\n",
    "# Group     0 (         System)\n",
    "# Group     1 (          Other)\n",
    "# Group     2 (            MOL)\n",
    "# Group     3 (         Custom)\n",
    "groups = \"10\"\n",
    "\n",
    "for cluster in tqdm(clusters):\n",
    "    cluster_workdir = f'gaff/{cluster}'\n",
    "    if not os.path.exists(cluster_workdir):\n",
    "        os.mkdir(cluster_workdir)\n",
    "        \n",
    "    shutil.copy(f'pdb_opt/{cluster}_opt.pdb', cluster_workdir)\n",
    "    shutil.copy('MOL.amb2gmx/MOL_GMX.top', cluster_workdir)\n",
    "    shutil.copy('em/em.mdp', cluster_workdir)\n",
    "    shutil.copy('md/md.mdp', cluster_workdir)\n",
    "    generate_restraint(cluster)\n",
    "    gmx_run(f'editconf -f {cluster}_opt.pdb -box 3 3 3 -bt cubic -c -o box.gro', workdir=cluster_workdir)\n",
    "    gmx_run('grompp -f em -c box.gro -p restrained.top -o em1', workdir=cluster_workdir)\n",
    "    gmx_run('mdrun -ntomp 2 -s em1 -c after_em1 -g em1 -e em1 -o em1', workdir=cluster_workdir)\n",
    "    gmx_run('grompp -f md -c box.gro -p MOL_GMX.top -o rerun', workdir=cluster_workdir)\n",
    "    gmx_run('mdrun -ntomp 2 -s rerun -rerun em1 -c after_rerun -g rerun -e rerun -o rerun', workdir=cluster_workdir)\n",
    "    gmx_run('energy -f rerun.edr -o rerun.xvg', workdir=cluster_workdir, groups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract gaff energies and from each energy value \n",
    "# subtract minimal energy\n",
    "\n",
    "gaff_energies = {}\n",
    "\n",
    "for cluster in clusters:\n",
    "    with open(f'gaff/{cluster}/rerun.xvg', 'r') as infile:\n",
    "        last_line = infile.readlines()[-1]\n",
    "        energies = last_line.split(' ')\n",
    "        gaff_energies[cluster] = energies[len(energies) - 1].rstrip()\n",
    "\n",
    "        \n",
    "min_energy = min(list(gaff_energies.values()))\n",
    "\n",
    "for cluster, energy in gaff_energies.items():\n",
    "    gaff_energies[cluster] = float(energy) - float(min_energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Define correction of force field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write corrected energy to final refernce.pdb file \n",
    "\n",
    "with open('reference.pdb', 'w') as outfile:\n",
    "    for cluster in clusters:\n",
    "        corrected_energy = orca_energies[cluster] - gaff_energies[cluster]\n",
    "        outfile.write(f'REMARK X={corrected_energy}\\n')\n",
    "        with open(f'pdb_opt/{cluster}_opt.pdb', 'r') as infile:\n",
    "            outfile.writelines(infile.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize final result of correction\n",
    "\n",
    "x1 = []\n",
    "y1 = []\n",
    "\n",
    "with open(\"DIHEDRALS\") as ifile:\n",
    "    for line in ifile.readlines():\n",
    "        split_values = line.split()\n",
    "        x1.append(float(split_values[1]))\n",
    "        y1.append(float(split_values[2]))\n",
    "\n",
    "plt.figure(figsize=(100, 50), dpi=100)\n",
    "plt.scatter(x, y, c='b', marker='.', label='All Configurations', s=2000)\n",
    "plt.scatter(x1, y1, c='r', marker='o', label='Representative optimized configurations', s=3000)\n",
    "plt.legend(loc='upper left', prop={'size': 80})\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
